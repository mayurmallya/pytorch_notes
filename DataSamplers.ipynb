{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://discuss.pytorch.org/t/some-problems-with-weightedrandomsampler/23242/34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset with imbalance\n",
    "\n",
    "class_counts = torch.tensor([700, 200, 100])\n",
    "num_data_points = class_counts.sum()\n",
    "data_dim = 5\n",
    "bs = 100\n",
    "data = torch.randn(num_data_points, data_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.cat((torch.zeros(class_counts[0], dtype=torch.long),\n",
    "                   torch.ones(class_counts[1], dtype=torch.long),\n",
    "                   torch.ones(class_counts[2], dtype=torch.long)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target train 0/1/2: 700/200/100\n"
     ]
    }
   ],
   "source": [
    "print('target train 0/1/2: {}/{}/{}'.format(\n",
    "     (target==0).sum(), (target==1).sum(), (target==2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute samples weight (each sample should get its own weight)\n",
    "\n",
    "class_sample_count = torch.tensor(\n",
    "    [(target == t).sum() for t in torch.unique(target, sorted=True)])\n",
    "weight = 1. / class_sample_count.float()\n",
    "samples_weight = torch.tensor([weight[t] for t in target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataset\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders with different sampling techniques\n",
    "\n",
    "dataloader_basic_sampler = torch.utils.data.DataLoader(train_dataset, batch_size=bs, num_workers=0)\n",
    "\n",
    "dataloader_basic_randomsampler = torch.utils.data.DataLoader(train_dataset, batch_size=bs, num_workers=0, shuffle=True)\n",
    "\n",
    "wrs = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "dataloader_weighterrandomsampler = torch.utils.data.DataLoader(train_dataset, batch_size=bs, num_workers=0, sampler=wrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic sampler\n",
      "batch index 0, 0/1/2: 100/0/0\n",
      "batch index 1, 0/1/2: 100/0/0\n",
      "batch index 2, 0/1/2: 100/0/0\n",
      "batch index 3, 0/1/2: 100/0/0\n",
      "batch index 4, 0/1/2: 100/0/0\n",
      "batch index 5, 0/1/2: 100/0/0\n",
      "batch index 6, 0/1/2: 100/0/0\n",
      "batch index 7, 0/1/2: 0/100/0\n",
      "batch index 8, 0/1/2: 0/100/0\n",
      "batch index 9, 0/1/2: 0/0/100\n",
      "Label distribution at the end \n",
      "of one epoch, 0/1/2: 700/200/100\n",
      "\n",
      " Basic random sampler\n",
      "batch index 0, 0/1/2: 78/12/10\n",
      "batch index 1, 0/1/2: 75/16/9\n",
      "batch index 2, 0/1/2: 67/22/11\n",
      "batch index 3, 0/1/2: 69/20/11\n",
      "batch index 4, 0/1/2: 61/27/12\n",
      "batch index 5, 0/1/2: 65/25/10\n",
      "batch index 6, 0/1/2: 76/13/11\n",
      "batch index 7, 0/1/2: 72/19/9\n",
      "batch index 8, 0/1/2: 69/23/8\n",
      "batch index 9, 0/1/2: 68/23/9\n",
      "Label distribution at the end \n",
      "of one epoch, 0/1/2: 700/200/100\n",
      "\n",
      " Weighted random sampler\n",
      "batch index 0, 0/1/2: 29/34/37\n",
      "batch index 1, 0/1/2: 32/32/36\n",
      "batch index 2, 0/1/2: 38/28/34\n",
      "batch index 3, 0/1/2: 32/35/33\n",
      "batch index 4, 0/1/2: 34/30/36\n",
      "batch index 5, 0/1/2: 35/32/33\n",
      "batch index 6, 0/1/2: 36/46/18\n",
      "batch index 7, 0/1/2: 25/44/31\n",
      "batch index 8, 0/1/2: 40/22/38\n",
      "batch index 9, 0/1/2: 44/31/25\n",
      "Label distribution at the end \n",
      "of one epoch, 0/1/2: 345/334/321\n"
     ]
    }
   ],
   "source": [
    "# Iterate DataLoader and check class balance for each batch\n",
    "\n",
    "acc = np.zeros(3)\n",
    "print('\\n Basic sampler')\n",
    "for i, (x, y) in enumerate(dataloader_basic_sampler):\n",
    "    print(\"batch index {}, 0/1/2: {}/{}/{}\".format(i, (y == 0).sum(), (y == 1).sum(), (y == 2).sum()))\n",
    "    acc += [(y == 0).sum(), (y == 1).sum(), (y == 2).sum()]\n",
    "print(\"Label distribution at the end \\nof one epoch, 0/1/2: {}/{}/{}\".format(int(acc[0]), int(acc[1]), int(acc[2])))\n",
    "    \n",
    "acc = np.zeros(3)    \n",
    "print('\\n Basic random sampler')\n",
    "for i, (x, y) in enumerate(dataloader_basic_randomsampler):\n",
    "    print(\"batch index {}, 0/1/2: {}/{}/{}\".format(i, (y == 0).sum(), (y == 1).sum(), (y == 2).sum()))\n",
    "    acc += [(y == 0).sum(), (y == 1).sum(), (y == 2).sum()]\n",
    "print(\"Label distribution at the end \\nof one epoch, 0/1/2: {}/{}/{}\".format(int(acc[0]), int(acc[1]), int(acc[2])))\n",
    "\n",
    "acc = np.zeros(3)\n",
    "print('\\n Weighted random sampler')\n",
    "for i, (x, y) in enumerate(dataloader_weighterrandomsampler):\n",
    "    print(\"batch index {}, 0/1/2: {}/{}/{}\".format(i, (y == 0).sum(), (y == 1).sum(), (y == 2).sum()))\n",
    "    acc += [(y == 0).sum(), (y == 1).sum(), (y == 2).sum()]\n",
    "print(\"Label distribution at the end \\nof one epoch, 0/1/2: {}/{}/{}\".format(int(acc[0]), int(acc[1]), int(acc[2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can observe that-\n",
    "\n",
    "####  - The basic sequential sampler simply loads the data sequentially and covers the entire dataset in one epoch.\n",
    "\n",
    "####  - The basic random sampler loads the data randomly and also covers the entire dataset in one epoch.\n",
    "\n",
    "####  - The weighted random sampler loads data randomly subject to the probabilities we assigned to the data labels. As it loads     data based on the imposed constraints, the loader cannot go through the entire dataset in one epoch. The minority class data points are seen multiple times in an epoch as the replacement option is set True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
